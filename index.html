<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>HDF5 Use Case, Liang2</title>
  <meta name="viewport" content="width=792, user-scalable=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <!-- Icon -->
  <link href="pics/favicon.png" rel="icon" type="image/x-icon" />
  <!-- MathJax -->
  <!-- CSS Stle -->
  <link rel="stylesheet" href="lib/shower/themes/ribbon/styles/screen.css">
  <link rel="stylesheet" href="lib/highlight/styles/tomorrow.css" type="text/css"/>
  <link rel="stylesheet" href="static/custom.css" type="text/css"/>
</head>
<body class="list">
  <!-- Header in overview -->
  <header class="caption">
    <h1>Convolutional Neural Network From the Ground Up</h1>
    <p style="line-height: 32px; padding-top:15px;"><a href="http://liang2.tw">Liang Bo Wang (亮亮)</a>, 2015-06-07</p>
  </header>

  <!-- START OF SLIDE CONTENT -->
  <!-- ABSTRACT
    HDF5 是一個用來存取數據的函式庫，Matlab 的儲存格式 (.mat) 即基於該格式設
    計。相較於多數人熟悉的 Database，HDF5 的功能更為單純，它只負責做好讀取、 儲
    存資料而並不提供 Query、Join 等操作，但也因此在 I/O 表現上更為出色。常見的
    應用為 sensor、實驗數據記錄與傳輸、大矩陣的操作等。HDF5 在 Python 的接口實
    作主要有 PyTables 及 h5py，兩者針對不同的使用情境有不同的設計。

    在本 talk 中，會先介紹 HDF5 格式與特色，在 Python 中如何用 PyTables、h5py
    存取 與異同，以及與主流資料庫、pickle 物件串流化的比較。最後示範 HDF5 如何
    有效的完成 以下幾個情境中的問題：存取 pandas DataFrame 物件、在大型矩陣進行
    區域計算、追蹤 Deep Learning 學習記錄。
  -->

  <!-- DESCRIPTION
    - 介紹 HDF5 特色
    - 介紹 h5py（直接實作 HDF5 API）用 Python 操作 HDF5 資料
    - 介紹 PyTables （支援一些 sorting、index 等查詢功能）
    - 為什麼不用內建的 pickle？
    - 為什麼不用 Database Ex MongoDB、SQLite、PostegreSQL？
    - 情境：HDF5 X pandas，可能是多數人最會用到的情境
      　　　使用 PyTables，並講解使用 h5py 的困難點
    - 情境：HDF5 X numpy，對大型矩陣計算
      　　　在計算大型影像（超過一億像素）中區域特徵，使用 HDF5 降低記憶體使用量，
    　　　  使得平行化變為可能。對多張圖計算時在 16 cores 上機器能達到 10 倍的效能提昇。
    - 情境：HDF5 X deep learning，追蹤模型學習記錄
      　　　Deep Learning 是複雜的類神經網路，可以學習的參數常在十萬到百萬量級，
    　　　  而常見使用 gradient decent 學習，透過迭代的方式更新參數。
    　　　  要追蹤這麼多參數就可以使用 HDF5 記錄。

    為什麼系列之所以會挑 pickle 與 database 有以下的原因：pickle 好處在於 hashable
    Python 物件都能直接轉，也是實務上最多人用的，但它的設計並不是為了快速存取大型資
    料，故在一些複雜的結構，或資料大小在 GB 級以上就會有問題。Database 是最多使用者
    想問題，這部份網路上也沒有什麼比較（因為應用差很多）但在這個講題就會用實際的
    benchmark 來舉例究竟差異有多明顯，提供聽眾在未來規劃分析時的參考。
  -->

  <!-- Cover slide -->
  <section id="cover" class="slide cover w"><div>
    <h3 id="talk-subheader">PyCon APAC 2015, 2015-06-07</h3>
    <h2 id="talk-header" class="place">HDF5 Use Case</h2>
    <p id="talk-author">
      By <a href="http://liang2.tw" target="_blank">Liang<sup>2</sup></a> under CC 4.0 BY license
    </p>
    <p id="usage-instr">
      <kbd>Esc</kbd> to overview <br />
      <kbd>←</kbd> <kbd>→</kbd> to navigate
    </p>
    <img src="pics/cover.jpg" alt="">
  </div>
  <style>
    #talk-header {
      color: #D91A3C;
      text-align: center;
      font-size: 120px;
      line-height: 1.2em;
      opacity: 0.8;
      position: relative;
      top: -20px;
      width: 120%;
    }
    #talk-subheader {
      color: #0376A6;
      text-align: center;
      font-size: 32px;
      opacity: 0.3;
      position: relative;
      top: -90px;
    }
    #talk-author {
      position: relative;
      line-height: 1.2em;
      text-shadow: 1px 1px 3px #000;
    }
    #talk-author {
      top: -20px;
    }
    #talk-author a {
      color: #FFFA20;
    }
    #cover p {
      margin: 10px 0 0;
      text-align: center;
      color: #FFF;
      font-size: 32px;
      opacity: 0.8;
    }
    #usage-instr {
      position: absolute;
      text-align: right;
      right: 30px;
      bottom: 20px;
    }
    #usage-instr kbd {
      opacity: 0.8;
      color: #D91A3C;
      background-color: white;
    }
    #cover .src-link {
      position: absolute;
      font-size: 14px;
      text-align: right;
      bottom: 10px;
      right: 10px;
    }
    #cover img {
      opacity: 1;
    }
  </style>
  </section>

  <section class="slide w shout"><div>
      <h2>A quick note before my talk</h2>
  </div></section>

  <section id="difference" class="slide w shout"><div>
      <h2>HDF<u>5</u> is NOT HDF<u>S</u></h2>
    </div>
    <style>
      #difference h2 {
        color: #D91A3C;
      }
    </style>
  </section>

  <section class="slide"><div>
    <h2>If you are expecting ...</h2>
    <ul class="tighter">
      <li>HDFS or Hadoop</li>
      <li>Big data</li>
      <li>Deep learning or how AI will rule the world</li>
      <li>IoT <span class="next">lol</span></li>
    </ul>
    <p>Wrong place. Talk of click detection by Vpon or sentimental analysis by Willy suits better. <b>Seriously</b>.</p>
  </div></section>

  <section id="code-fight" class="slide cover w"><div>
    <p>Unexpected code fight and online judge</p>
    <img src="pics/code_fight.jpg" alt="">
    <style>
      #code-fight p {
        color: white;
        font-size: 46px;
        position: absolute;
        bottom: 0px;
      }
    </style>
  </div></section>

  <section id="about-me" class="slide"><div>
      <h2>About Me</h2>
      <ul>
        <li>Master student at <br />
          Bioinfo &amp; Biostat Core Lab, NTU CGM</li>
        <li>R / Python</li>
        <li>Taiwan R co-organizer</li>
        <li>PyCon APAC 2014-15/TW staff</li>
        <li>Former intern at Microsoft Research Asia</li>
        <li>Happy to chat about Bioinfo <del>and anime</del></li>
      </ul>
      <img id="protrait" src="pics/me.jpg" class="place r"alt="">
    </div>
    <style>
      #protrait {
        margin-right: 120px;
        width: 300px;
      }
    </style>
  </section>

  <section id="hdf5-resource" class="slide twocol-ll"><div>
    <h2>Many good HDF5 intros out there already</h2>
    <div class="left">
    <ul>
      <li>The API is clean and easy to learn oneself</li>
      <li>Details are in the book <span class="next">（據說天瓏有賣）</span></li>
      <li>I'm not going(able) to create another one</li>
      <li>Concepts and my use cases</li>
    </ul>
    </div>
    <div class="right">
    <div class="citation">
      <img src="pics/external/Python_and_HDF5.png" alt="">
      <p>Ref: <a href="http://shop.oreilly.com/product/0636920030249.do">Python and HDF5, Oreilly</a></p>
    </div>
    </div>
  </div></section>

  <section id="hdf5-intro-cover" class="slide cover w subheader"><div>
      <h2>HDF5 Intro</h2>
      <img src="pics/mid.jpg" alt="">
    </div>
  </section>

  <section class="slide"><div>
    <h2>HDF = Hierarchical Data Format</h2>
    <ul>
      <li><b>Structure data with meta data</b><D-r></li>
      <li>Focus on fast (partial) I/O</li>
      <li>A stable and structural way to store large numerical data thru continuous development for 20+ years</li>
      <li>BSD-like license</li>
      <li>Commonly seen in scientific research projects. Ex LHC, NASA</li>
      <li>Current format version: HDF5</li>
    </ul>
  </div></section>

  <section class="slide"><div>
    <h2>Readable by most programming languages</h2>
    <ul>
      <li><b>Python</b>: h5py and PyTables. Talk most about h5py today</li>
      <li><b>R</b>: rhdf5 (on Bioconductor)</li>
      <li><b>Lua</b>: HDF5 or Torch-hdf5</li>
      <li><b>Matlab</b>: built-in support and <code>.mat</code> file bases on HDF5</li>
      <li><b>Mathematica</b>: built-in support</li>
    </ul>
  </div></section>

  <section class="slide"><div>
    <h2>Keep data organized and connected by design</h2>
    <pre class="language-python">
    <code>import h5py
f = h5py.File("weather.hdf5", "a")
f['/taipei_1/humidity'] = np.array(...)
f['/taipei_1/humidity'].attrs['rec_date'] = utc_timestamp
f['/taipei_1/temperature'] = np.array(...)
dataset = f['/taipei_5/humidity']
    </code></pre>
  </div></section>

  <section class="slide"><div>
    <h2>Group and dataset</h2>
    <pre class="language-python">
<code>'''f['/taipei_1/these_days/humidity']
      ---------------------========
        group     group    dataset
'''
tpe_grp = f.create_group('taipei_1')
these_days = tpe_grp.create_group('these_days')
humidity = these_days.create_dataset('humidity', ...)
     </code></pre>
  </div></section>

  <section class="slide"><div>
    <h2>Datasets creation</h2>
    <pre class="language-python">
<code>dset = f.create_dataset(
  "demo",
  (10, 10),           # dset.shape, can be multi-dim
  dtype=np.float64,   # dset.dtype like Numpy
  fillvalue=42        # default value
)
dset[:5, :5] = np.arange(25).reshape((5, -1))
</code></pre>
  </div></section>

  <section class="slide"><div>
    <h2>Dataset partial reading</h2>
    <pre class="language-python">
<code>out = dset[:5, :5]

# More efficiently
out = np.empty((100, 50), dtype=np.float32)
dset.read_direct(out, np.s_[:, 0:50])
</code></pre>
  </div></section>

  <section class="slide"><div>
    <h2>Chunks</h2>
    <ul class="tighter">
      <li>Chunks help jumping over the HDF5 file faster</li>
      <li>A chunk can only be loaded fully (and cached)</li>
      <li>Chunk too large or small don't help, creating large index overhead<D-r></li>
    </ul>
    <pre class="language-python">
<code>f.create_dataset(
    'classA_heart_beat',
    (100, 3600),    # 1hr heart rate rec for every 1sec
    # 1 chunk = 8 * 3600 bytes = 28.8KB
    chunks=(1, 3600), dtype=np.int8)</code>
    </pre>
  </div></section>

  <section class="slide"><div>
    <h2>Compression and filter</h2>
    <ul>
      <li>For cross-platform compatibility, use GZIP though slower</li>
      <li>Filter further increase the efficiency of compression</li>
    </ul>
    <pre><code>create_dataset(.., compression="gzip", shuffle=True)</code></pre>
  </div></section>

  <section class="slide"><div>
    <h2>Datasets - metadata</h2>
    <pre class="language-python">
<code>dset = f.create_dataset(...)
dset.attrs['title'] = 'PyCon APAC'
dset.attrs['year'] = 2015</code>
    </pre>
  </div></section>

  <section class="slide"><div>
    <h2>Tricky things - Strings</h2>
    <ul class="tighter">
      <li>Fixed-length ASCII / Unicode strings are supported.</li>
      <li>Variable length? Converted to Numpy object</li>
      <li>Variable-length Unicode? Tricky and not cross-platform.</li>
    </ul>
    <pre class="language-python">
<code>>>> dt = h5py.special_dtype(vlen=str)
>>> dt
dtype(('|O4', [(({'type': <type 'str'>}, 'vlen'), '|O4')]))</code>
    </pre>
  </div></section>

  <section class="slide"><div>
    <h2>Good things - Concurrency</h2>
    <ul>
      <li>One connection for R/W and others for R only is a good paradigm</li>
      <li>HDF5 by default not thread-safe</li>
      <li>HDF5 compiled in parallel mode works seamlessly with MPI</li>
    </ul>
  </div></section>

  <section id="x-vs-hdf5-cover" class="slide cover w subheader"><div>
      <h2>How about<br>X vs HDF5?</h2>
      <img src="pics/mid.jpg" alt="">
    </div>
  </section>

  <section id="pickle" class="slide twocol"><div>
    <div class="left">
      <h2>Pickle the awesome</h2>
      <ul>
        <li><b>Want something to save in no-brain? Use pickle</b></li>
        <li>Once addicted no one gets back</li>
        <li class="next">Save a list of 1M elements? Use pickle</li>
        <li class="next">Save the IPython parallel async metadata? Use pickle</li>
        <li class="next"><b>Save but fail to load</b></li>
      </ul>
    </div>
    <div class="right">
      <pre class="language-python">
<code>
class MyConfig:
    def __init__(self, ...):
        self.x = x
        self.y = y
        # ...

c = MyConfig()
pickle.dump(c)
c = pickle.load(pickle_pth)
</code></pre>
    </div>
  </div></section>

  <section class="slide"><div>
      <h2>Pickle vs HDF5</h2>
      <ul>
        <li>Pickle is no-brainer so good for prototype</li>
        <li>Workable for one's own class and object</li>
        <li>Not that workable for others Py object if not knowing the detail</li>
        <li>Save a 8GB model in pickle? <b>High memory overhead</b></li>
        <li>Slower than HDF5</li>
      </ul>
  </div></section>

  <section class="slide"><div>
      <h2>Numpy save / load</h2>
      <p><code>.npy, .npz</code> are bascially a ZIP format.</p>
      <pre class="language-python">
<code>>>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))
>>> np.load('/tmp/123.npy')
array([[1, 2, 3],
       [4, 5, 6]])</code></pre>
  </div></section>

  <section class="slide"><div>
      <h2>You said to save data? Database?</h2>
      <ul>
        <li>Most frequent question people asked about HDF5</li>
        <li>SQLite, MongoDB, ... name it</li>
        <li>They are designed for different purpose</li>
        <li class="next"><b>Database supports performant index, search, table merge</b></li>
        <li class="next"><b>HDF5 focuses on I/O and storage and it works better</b></li>
      </ul>
  </div></section>

  <section class="slide"><div>
      <h2>Database vs HDF5</h2>
      <ul>
        <li>Expect (also in our test) at least 1 order slower than HDF5 on one machine</li>
        <li>Database is still good for what you know</li>
        <li>"Have you tested Cassandra cluster?" okay ... I don't know which better when it comes to cluster or more complex architecture.</li>
        <li>HDF5 doesn't handle string that well</li>
        <li>HDF5 doesn't have index, search and join.</li>
      </ul>
  </div></section>

  <section class="slide"><div>
      <h2>Why not makes HDF5 support those awesomeness?</h2>
      <img class="next" src="pics/external/pytables.png" alt="">
      <p class="next">Some optimization comparision on <a href="http://www.pytables.org/usersguide/optimization.html">their official site</a></p>
      <p class="next">Back on this later. <span>Simply put, it reduces the cross-platform ability</span></p>
  </div></section>

  <section id="hdf5-usecase-cover" class="slide cover w subheader"><div>
      <h2>HDF5<br>Use Case</h2>
      <img src="pics/mid.jpg" alt="">
    </div>
  </section>

  <section class="slide"><div>
    <h2>Daily - Pandas X HDF5</h2>
    <ul>
      <li><code>df.to_hdf5(...)</code> with PyTables</li>
      <li>Support many kinds of pandas axes and searching</li>
      <li>The saved HDF5 files have more complex structure</li>
      <li>Writing a special methods for certain dataframe columns</li>
      <li><b>Stop reading from CSV or other text files everytime</b></li>
    </ul>

  </div></section>

  <section class="slide"><div>
    <h2>Large Numpy array X HDF5</h2>
    <ul>
      <li>One of my project back in MSRA</li>
      <li>Digital histopathology image analysis</li>
      <li>Biopy comes with 10,000 x 10,000+ pixels</li>
      <li>Analyze by 256 x 256 patches</li>
      <li>In the end plot a heatmap</li>
      <li>Don't want to understand how to efficiently read TIFF</li>
    </ul>
  </div></section>

  <section class="slide w"><div>
    <img style="width: 100%;" src="pics/external/histopatholgy_analysis.png" alt="">
    <p>Something like this</p>
  </div></section>

  <section class="slide"><div>
    <h2>Original way</h2>
    <ul>
      <li>Read the TIFF (large memory)</li>
      <li>Work it by patch</li>
      <li>Save after all patches finish</li>
      <li>Large memory use (> 30GB), 1 CPU active</li>
    </ul>
  </div></section>

  <section class="slide"><div>
    <h2>Handled by HDF5</h2>
    <ul>
      <li>Save raw image in HDF5</li>
      <li>read it by patch and save it by patch</li>
      <li>Very low memory usage (< 500MB)</li>
      <li>Parallel for 24 cores, get a 15-fold boost</li>
    </ul>
  </div></section>

  <section class="slide"><div>
    <pre class="language-python">
    <code>
with h5py.File(hdf5_pth, 'w') as f:
    for batch in img_batches:
        region_data = f['raw_img_xx'][batch.region]
        # ...
        f['heatmap_img_xx'][batch.region] = outcome
</code></pre>
  </div></section>

  <section class="slide"><div>
      <h2>Deep learning x HDF5</h2>
      <div class="citation">
        <img src="pics/external/cs231n_note_cnn_arch.png" alt="">
        <p>Ref: <a href="http://cs231n.github.io/convolutional-networks/">CS231n Note: Convolutional Netowrks</a></p>
      </div>
      <p>Input viewed as 32 width x 32 height x 3 channels (depth)<br>
        Output viewed as 1 x 1 x 10. Spatial information is preserved.</p>
  </div></section>

  <section class="slide"><div>
      <h2>Learning process</h2>
      <pre class="language-python"><code># evaluate loss and gradient, internally use self.W
loss, grad = self.loss(X_batch, y_batch, reg)
loss_history.append(loss)

# perform parameter update
self.W -= grad * learning_rate</code></pre>
  </div></section>

  <section id="comp-param-update" class="slide"><div>
      <h2 class="tighter">Parameter update method comparison</h2>
      <div class="citation">
        <div class="twocol">
          <img src="pics/external/cs231n_note_opt1.gif" alt="">
          <img src="pics/external/cs231n_note_opt2.gif" alt="">
        </div>
        <p class="note">Animations that may help your intuitions about the learning process dynamics. <strong>Left</strong>: Contours of a loss surface and time evolution of different optimization algorithms. Notice the "overshooting" behavior of momentum-based methods, which make the optimization look like a ball rolling down the hill. <strong>Right</strong>: A visualization of a saddle point in the optimization landscape, where the curvature along different dimension has different signs (one dimension curves up and another down). Notice that SGD has a very hard time breaking symmetry and gets stuck on the top. Conversely, algorithms such as RMSprop will see very low gradients in the saddle direction. Tue to the denominator term in the RMSprop update, this will increase the effective learning rate along this direction, helping RMSProp proceed.
        </p>
        <p>Ref: <a href="http://cs231n.github.io/neural-networks-3/">CS231n Note: Neural Network 3</a> and Image credit: <a href="https://twitter.com/alecrad">Alec Radford</a>.</p>
      </div>
      <style>
        #comp-param-update .citation .twocol {
          text-align: center;
        }
        #comp-param-update .citation .twocol > img:nth-child(1) {
          margin-left: auto;
          width: 47%;
        }
        #comp-param-update .citation .twocol> img:nth-child(2) {
          width: 47%;
        }
        #comp-param-update .citation > p:not(.note) {
          margin-top: 10px;
          margin-right: 15px;
        }
        #comp-param-update .citation > p.note {
          margin-top: 0px;
          margin-right: 15px;
          margin-left: 15px;
          text-align: left;
          font-size: 14px;
          line-height: 18px;
          color: #888;
        }

      </style>
  </div></section>

  <section class="slide"><div>
      <h2>How to track the learning progress for all parameters</h2>
      <ul>
        <li>1M+ parameters for a modern CNN model</li>
        <li>Learning rate is hard to tune</li>
        <li>Track 1M+ parameters update for 1000+ iterations?</li>
        <li>Use HDF5 to store the parameter history</li>
      </ul>
  </div></section>

  <section class="slide"><div>
      <h2>RPi2 X HDF5</h2>
      <ul>
        <li>Firstly, thanks Kano for sending me RPi2 fast and sound</li>
        <li>Some good hackable platform with strong ecosystem</li>
        <li>The application is replacable with normal database</li>
      </ul>
  </div></section>

  <section class="slide cover w"><div>
      <img src="pics/fish_tank.JPG" alt="">
  </div></section>

  <section class="slide cover w"><div>
      <img src="pics/plant1.JPG" alt="">
  </div></section>

  <section class="slide twocol"><div>
      <div class="left">
        <h2>Long term monitoring</h2>
        <ul>
          <li>Continuous storage of sensor data</li>
          <li>Group by date</li>
          <li>Monitor and alert</li>
        </ul>
      </div>
      <div class="right">
        <img style="width: 100%;" src="pics/plant2.JPG" alt="">
      </div>
  </div></section>

  <section class="slide"><div>
      <h2>Recap</h2>
      <ul>
        <li>HDF5 = Hierarchical Data Format</li>
        <li>Group, dataset, chunck, compression</li>
        <li>Large numerical matrix on disk</li>
        <li>Robust and cross-platform</li>
      </ul>
  </div></section>

  <!-- End Slide -->
  <section id='end' class='slide cover shout w'><div>
    <h2>Thank You!</h2>
    <img src="pics/end.jpg" alt="">
  </div><style>
    #end h2 {
      position: absolute;
      text-align: left;
      top: 200px;
      left: 80px;
      color: yellow;
      font-size: 92px;
      opacity: 0.9;
    }
  </style></section>

  <!-- END OF SLIDE CONTENT -->
  <p class="badge"><a href="https://github.com/ccwang002/2015Talk-DeepLearn-CNN" target="_blank">Fork me on Github</a></p>
  <div class="progress"><div></div></div>

  <!-- Library -->
  <script src="lib/highlight/highlight.pack.js" type="text/javascript" charset="utf-8"></script>
  <script>
    hljs.initHighlightingOnLoad();
  </script>
  <script src="lib/shower/shower.min.js"></script>
  <!-- Mathjax -->
  <!-- During local development, use localhost mathjax for speed-->
  <!--<script src="file:///Users/liang/.ipython/profile_default/static/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
  <!-- online Mathjax CDN -->
  <!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
</body>
</html>
